{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be737ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.4.4)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.5.4-cp310-cp310-macosx_11_0_arm64.whl (6.6 MB)\n",
      "Requirement already satisfied: contractions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.1.73)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: spacy-cleaner in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.1.3)\n",
      "Requirement already satisfied: pyspellchecker in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.7.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.64.1)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.13.1)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0rc2-cp310-cp310-macosx_12_0_arm64.whl (2.0 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (63.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4) (2.4.1)\n",
      "Requirement already satisfied: spacy-lookups-data<1.1.0,>=1.0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy-cleaner) (1.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Collecting tensorflow-macos==2.13.0-rc2 (from tensorflow)\n",
      "  Downloading tensorflow_macos-2.13.0rc2-cp310-cp310-macosx_12_0_arm64.whl (189.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting astunparse>=1.6.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading h5py-3.9.0-cp310-cp310-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading libclang-16.0.0-py2.py3-none-macosx_11_0_arm64.whl (24.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc2->tensorflow) (4.21.12)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc2->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-macosx_11_0_arm64.whl (36 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc2->tensorflow) (1.51.1)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0rc0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyascii in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0-rc2->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (0.8.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-estimator, tensorboard-data-server, opt-einsum, markdown, h5py, google-pasta, gast, astunparse, absl-py, tensorboard, tensorflow-macos, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.6.3\n",
      "    Uninstalling typing_extensions-4.6.3:\n",
      "      Successfully uninstalled typing_extensions-4.6.3\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.4.0 google-pasta-0.2.0 h5py-3.9.0 libclang-16.0.0 markdown-3.4.3 opt-einsum-3.3.0 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0rc2 tensorflow-estimator-2.13.0 tensorflow-macos-2.13.0rc2 termcolor-2.3.0 typing-extensions-4.5.0 werkzeug-2.3.6 wrapt-1.15.0\n",
      "Collecting en-core-web-lg==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from en-core-web-lg==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (63.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip3 install -U spacy contractions beautifulsoup4 spacy-cleaner pyspellchecker requests pandas scikit-learn tqdm matplotlib seaborn keras tensorflow\n",
    "!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ccf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "from spellchecker import SpellChecker\n",
    "import en_core_web_lg\n",
    "import spacy\n",
    "import requests\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e464ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "5  Probably my all-time favorite movie, a story o...  positive\n",
      "6  I sure would like to see a resurrection of a u...  positive\n",
      "7  This show was an amazing, fresh & innovative i...  negative\n",
      "8  Encouraged by the positive comments about this...  negative\n",
      "9  If you like original gut wrenching laughter yo...  positive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory data analysis\n",
    "imdb_data = pd.read_csv('input/imdb_dataset.csv')\n",
    "print(imdb_data.head(10))\n",
    "imdb_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfdaac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slang_dict() -> dict:\n",
    "    '''Method to retrieve a dictionary of slang phrases and its actual meanings\n",
    "    \n",
    "    Returns\n",
    "        str: Tokenized text\n",
    "    '''\n",
    "    abbr_dict = {}\n",
    "    def getAbbr(alpha, abbr_dict):\n",
    "        res = requests.get('https://www.noslang.com/dictionary/'+alpha)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        for abbr in soup.find_all('abbr'):\n",
    "            full = abbr['title'].lower()\n",
    "            abrv = abbr.find('dt').text[:-2]\n",
    "            abbr_dict[abrv] = full\n",
    "    abbr_list = []\n",
    "    for char in range(97,123):\n",
    "        abbr_list.append(chr(char))\n",
    "    for i in abbr_list:\n",
    "        getAbbr(i, abbr_dict)\n",
    "    return abbr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1333671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_review(review: str) -> str:\n",
    "    '''Method to normalize (preprocess and lemmatize) a review into a tokenized list of words\n",
    "    Steps:\n",
    "        1. HTML decoding\n",
    "        2. Lowercase conversion\n",
    "        3. Contractions expansion\n",
    "        4. Entities detection\n",
    "        5. Digits and punctuations removal\n",
    "        5. Slang correction\n",
    "        6. Spelling correction\n",
    "        7. Word tokenization\n",
    "        8. Stop words removal and removal of insignificant words (less than 2 characters)\n",
    "        9. Lemmatization\n",
    "    \n",
    "    Required Args\n",
    "        review (str): Text to be preprocessed\n",
    "    \n",
    "    Returns\n",
    "        str: Tokenized text\n",
    "    '''\n",
    "    # HTML decoding\n",
    "    review = BeautifulSoup(review).get_text()\n",
    "    # Convert words to lowercase\n",
    "    review = review.lower()\n",
    "    # Expand contractions\n",
    "    review_list = []\n",
    "    for word in review.split():\n",
    "        review_list.append(contractions.fix(word))\n",
    "    review = ' '.join(review_list)\n",
    "    # Make entities a single token eg. New York -> New-York\n",
    "    nlp = en_core_web_lg.load()\n",
    "    entity_list = []\n",
    "    for ele in nlp(review).ents:\n",
    "        if len(str(ele.text).split()) > 1:\n",
    "            entity_list.append((ele.text, str(ele.text).replace(' ','_')))\n",
    "    for item in entity_list:\n",
    "        review = review.replace(item[0], item[1])\n",
    "    # Digits and punctuations removal\n",
    "    review_list = re.sub('[^a-zA-Z0-9_]', ' ', review).split()\n",
    "    review_list = [word for word in review_list if not re.search(r'\\d', word)]\n",
    "    review = ' '.join(review_list)\n",
    "    # Correct slang words / phrases\n",
    "    global abbr_dict\n",
    "    expanded = {}\n",
    "    for word in review_list:\n",
    "        if word in abbr_dict:\n",
    "            expanded[word] = abbr_dict[word]\n",
    "    for item in expanded:\n",
    "        review = review.replace(item, expanded[item])\n",
    "    # Correct spelling\n",
    "    review_list = review.split()\n",
    "    corrector = SpellChecker()\n",
    "    misspelled = corrector.unknown(review_list)\n",
    "    corrected = {}\n",
    "    for word in misspelled:\n",
    "        if corrector.correction(word):\n",
    "            corrected[word] = corrector.correction(word)\n",
    "    review = ' '.join(review_list)\n",
    "    for item in corrected:\n",
    "        review = review.replace(item, corrected[item])\n",
    "    # Word tokenization, stop word removal and lemmatization\n",
    "    doc = nlp(review)\n",
    "    tokenized_word_list = []\n",
    "    for token in doc:\n",
    "        if '_' in token.text:\n",
    "            tokenized_word_list.append(token.text)\n",
    "        elif not token.is_stop and len(token.text) > 1:\n",
    "            # Lemmatization\n",
    "            tokenized_word_list.append(token.lemma_)\n",
    "    return ' '.join(tokenized_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f969884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/_nztlx510ng_bk9rwth0cg280000gn/T/ipykernel_86298/1609383967.py:22: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review = BeautifulSoup(review).get_text()\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "abbr_dict = get_slang_dict()\n",
    "imdb_data['review'] = imdb_data['review'].apply(normalize_review)\n",
    "imdb_data = imdb_data[['review', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73497690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reviewer mention watch episode hook right exac...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production film technique ii ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think thii wai wonderful way ipend time hot iu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter_matter love time money ii viiually itun...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>probably time favorite movie itory ielfleiinei...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iure like iee reiurrection date ihunt ieriei t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thii ihow wai amazing freih innovative idea fi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>encourage poiitive commenti thii film wai look...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>like original gut wrench laughter like movie y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  reviewer mention watch episode hook right exac...  positive\n",
       "1  wonderful little production film technique ii ...  positive\n",
       "2  think thii wai wonderful way ipend time hot iu...  positive\n",
       "3  basically family little boy jake think zombie ...  negative\n",
       "4  petter_matter love time money ii viiually itun...  positive\n",
       "5  probably time favorite movie itory ielfleiinei...  positive\n",
       "6  iure like iee reiurrection date ihunt ieriei t...  positive\n",
       "7  thii ihow wai amazing freih innovative idea fi...  negative\n",
       "8  encourage poiitive commenti thii film wai look...  negative\n",
       "9  like original gut wrench laughter like movie y...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6311796",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, y_train), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m, y_test)]):\n\u001b[0;32m----> 7\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m()\n\u001b[1;32m      8\u001b[0m     sns\u001b[38;5;241m.\u001b[39mbarplot(ax\u001b[38;5;241m=\u001b[39max[idx], x\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex, y\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      9\u001b[0m     ax[idx]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Label Count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value_counts'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAGyCAYAAABk/q6oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh0klEQVR4nO3db2xd5X3A8Z/t4GtQsQnLYieZaQYdpS2Q0IR4hiLE5NUSKF1eTM2gSrKIP6PNEI21lYRAXEobZwxQpGIakcLoi7KkRYCqJjKjXqOK4ilqEkt0JCAaaLKqNsk67My0NrHPXiDcmTg015z72Amfj3Rf5HCO73MfOfzy9b2+tyzLsiwAAACAkiqf7AUAAADAh4EABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEhDgAAAAkIAABwAAgASKDvCf/OQnsXjx4pg9e3aUlZXFM8888wev2blzZ3z605+OQqEQH/vYx+Lxxx+fwFIBgBTMegAojaIDfGBgIObNmxft7e0ndf5rr70W1113XVxzzTXR3d0dX/7yl+Omm26KZ599tujFAgClZ9YDQGmUZVmWTfjisrJ4+umnY8mSJSc854477ojt27fHz3/+89Fjf/M3fxNvvvlmdHR0TPSuAYAEzHoAyM+0Ut9BV1dXNDU1jTnW3NwcX/7yl094zeDgYAwODo7+eWRkJH7zm9/EH/3RH0VZWVmplgoAJyXLsjh69GjMnj07ysu9nYpZD8DpqBTzvuQB3tPTE7W1tWOO1dbWRn9/f/z2t7+NM88887hr2tra4p577in10gDgAzl06FD8yZ/8yWQvY9KZ9QCczvKc9yUP8IlYu3ZttLS0jP65r68vzjvvvDh06FBUV1dP4soAIKK/vz/q6+vj7LPPnuylnLLMegCmulLM+5IHeF1dXfT29o451tvbG9XV1eP+RDwiolAoRKFQOO54dXW1oQzAlOGl0u8w6wE4neU570v+i2uNjY3R2dk55thzzz0XjY2Npb5rACABsx4ATk7RAf6///u/0d3dHd3d3RHxzkePdHd3x8GDByPinZeULV++fPT8W2+9NQ4cOBBf+cpXYv/+/fHwww/H9773vVi9enU+jwAAyJVZDwClUXSA/+xnP4vLLrssLrvssoiIaGlpicsuuyzWr18fERG//vWvRwd0RMSf/umfxvbt2+O5556LefPmxQMPPBDf/va3o7m5OaeHAADkyawHgNL4QJ8Dnkp/f3/U1NREX1+f3wsDYNKZS/mzpwBMNaWYTT68FAAAABIQ4AAAAJCAAAcAAIAEBDgAAAAkIMABAAAgAQEOAAAACQhwAAAASECAAwAAQAICHAAAABIQ4AAAAJCAAAcAAIAEBDgAAAAkIMABAAAgAQEOAAAACQhwAAAASECAAwAAQAICHAAAABIQ4AAAAJCAAAcAAIAEBDgAAAAkIMABAAAgAQEOAAAACQhwAAAASECAAwAAQAICHAAAABIQ4AAAAJCAAAcAAIAEBDgAAAAkIMABAAAgAQEOAAAACQhwAAAASECAAwAAQAICHAAAABIQ4AAAAJCAAAcAAIAEBDgAAAAkIMABAAAgAQEOAAAACQhwAAAASECAAwAAQAICHAAAABIQ4AAAAJCAAAcAAIAEBDgAAAAkIMABAAAgAQEOAAAACQhwAAAASECAAwAAQAICHAAAABIQ4AAAAJCAAAcAAIAEBDgAAAAkIMABAAAgAQEOAAAACQhwAAAASECAAwAAQAICHAAAABIQ4AAAAJCAAAcAAIAEBDgAAAAkIMABAAAgAQEOAAAACQhwAAAASECAAwAAQAICHAAAABIQ4AAAAJDAhAK8vb095s6dG1VVVdHQ0BC7du163/M3bdoUH//4x+PMM8+M+vr6WL16dfzud7+b0IIBgNIz6wEgf0UH+LZt26KlpSVaW1tjz549MW/evGhubo433nhj3POfeOKJWLNmTbS2tsa+ffvi0UcfjW3btsWdd975gRcPAOTPrAeA0ig6wB988MG4+eabY+XKlfHJT34yNm/eHGeddVY89thj457/wgsvxJVXXhk33HBDzJ07Nz772c/G9ddf/wd/kg4ATA6zHgBKo6gAHxoait27d0dTU9Pvv0B5eTQ1NUVXV9e411xxxRWxe/fu0SF84MCB2LFjR1x77bUnvJ/BwcHo7+8fcwMASs+sB4DSmVbMyUeOHInh4eGora0dc7y2tjb2798/7jU33HBDHDlyJD7zmc9ElmVx7NixuPXWW9/3ZWltbW1xzz33FLM0ACAHZj0AlE7J3wV9586dsWHDhnj44Ydjz5498dRTT8X27dvj3nvvPeE1a9eujb6+vtHboUOHSr1MAGCCzHoAODlFPQM+Y8aMqKioiN7e3jHHe3t7o66ubtxr7r777li2bFncdNNNERFxySWXxMDAQNxyyy2xbt26KC8//mcAhUIhCoVCMUsDAHJg1gNA6RT1DHhlZWUsWLAgOjs7R4+NjIxEZ2dnNDY2jnvNW2+9ddzgraioiIiILMuKXS8AUEJmPQCUTlHPgEdEtLS0xIoVK2LhwoWxaNGi2LRpUwwMDMTKlSsjImL58uUxZ86caGtri4iIxYsXx4MPPhiXXXZZNDQ0xKuvvhp33313LF68eHQ4AwBTh1kPAKVRdIAvXbo0Dh8+HOvXr4+enp6YP39+dHR0jL5Zy8GDB8f8FPyuu+6KsrKyuOuuu+JXv/pV/PEf/3EsXrw4vvGNb+T3KACA3Jj1AFAaZdkp8Nqw/v7+qKmpib6+vqiurp7s5QDwIWcu5c+eAjDVlGI2lfxd0AEAAAABDgAAAEkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAlMKMDb29tj7ty5UVVVFQ0NDbFr1673Pf/NN9+MVatWxaxZs6JQKMSFF14YO3bsmNCCAYDSM+sBIH/Tir1g27Zt0dLSEps3b46GhobYtGlTNDc3x8svvxwzZ8487vyhoaH4y7/8y5g5c2Y8+eSTMWfOnPjlL38Z55xzTh7rBwByZtYDQGmUZVmWFXNBQ0NDXH755fHQQw9FRMTIyEjU19fHbbfdFmvWrDnu/M2bN8c///M/x/79++OMM86Y0CL7+/ujpqYm+vr6orq6ekJfAwDycrrPJbMeAEozm4p6CfrQ0FDs3r07mpqafv8Fysujqakpurq6xr3mBz/4QTQ2NsaqVauitrY2Lr744tiwYUMMDw+f8H4GBwejv79/zA0AKD2zHgBKp6gAP3LkSAwPD0dtbe2Y47W1tdHT0zPuNQcOHIgnn3wyhoeHY8eOHXH33XfHAw88EF//+tdPeD9tbW1RU1Mzequvry9mmQDABJn1AFA6JX8X9JGRkZg5c2Y88sgjsWDBgli6dGmsW7cuNm/efMJr1q5dG319faO3Q4cOlXqZAMAEmfUAcHKKehO2GTNmREVFRfT29o453tvbG3V1deNeM2vWrDjjjDOioqJi9NgnPvGJ6OnpiaGhoaisrDzumkKhEIVCoZilAQA5MOsBoHSKega8srIyFixYEJ2dnaPHRkZGorOzMxobG8e95sorr4xXX301RkZGRo+98sorMWvWrHEHMgAwecx6ACidol+C3tLSElu2bInvfOc7sW/fvvjiF78YAwMDsXLlyoiIWL58eaxdu3b0/C9+8Yvxm9/8Jm6//fZ45ZVXYvv27bFhw4ZYtWpVfo8CAMiNWQ8ApVH054AvXbo0Dh8+HOvXr4+enp6YP39+dHR0jL5Zy8GDB6O8/PddX19fH88++2ysXr06Lr300pgzZ07cfvvtcccdd+T3KACA3Jj1AFAaRX8O+GTw2aAATCXmUv7sKQBTzaR/DjgAAAAwMQIcAAAAEhDgAAAAkIAABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEhDgAAAAkIAABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEhDgAAAAkIAABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEhDgAAAAkIAABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEhDgAAAAkIAABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEhDgAAAAkIAABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEhDgAAAAkIAABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEhDgAAAAkIAABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEphQgLe3t8fcuXOjqqoqGhoaYteuXSd13datW6OsrCyWLFkykbsFABIx6wEgf0UH+LZt26KlpSVaW1tjz549MW/evGhubo433njjfa97/fXX4x/+4R/iqquumvBiAYDSM+sBoDSKDvAHH3wwbr755li5cmV88pOfjM2bN8dZZ50Vjz322AmvGR4eji984Qtxzz33xPnnn/+BFgwAlJZZDwClUVSADw0Nxe7du6Opqen3X6C8PJqamqKrq+uE133ta1+LmTNnxo033nhS9zM4OBj9/f1jbgBA6Zn1AFA6RQX4kSNHYnh4OGpra8ccr62tjZ6ennGvef755+PRRx+NLVu2nPT9tLW1RU1Nzeitvr6+mGUCABNk1gNA6ZT0XdCPHj0ay5Ytiy1btsSMGTNO+rq1a9dGX1/f6O3QoUMlXCUAMFFmPQCcvGnFnDxjxoyoqKiI3t7eMcd7e3ujrq7uuPN/8YtfxOuvvx6LFy8ePTYyMvLOHU+bFi+//HJccMEFx11XKBSiUCgUszQAIAdmPQCUTlHPgFdWVsaCBQuis7Nz9NjIyEh0dnZGY2PjcedfdNFF8eKLL0Z3d/fo7XOf+1xcc8010d3d7eVmADDFmPUAUDpFPQMeEdHS0hIrVqyIhQsXxqJFi2LTpk0xMDAQK1eujIiI5cuXx5w5c6KtrS2qqqri4osvHnP9OeecExFx3HEAYGow6wGgNIoO8KVLl8bhw4dj/fr10dPTE/Pnz4+Ojo7RN2s5ePBglJeX9FfLAYASMusBoDTKsizLJnsRf0h/f3/U1NREX19fVFdXT/ZyAPiQM5fyZ08BmGpKMZv8+BoAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQwIQCvL29PebOnRtVVVXR0NAQu3btOuG5W7ZsiauuuiqmT58e06dPj6ampvc9HwCYfGY9AOSv6ADftm1btLS0RGtra+zZsyfmzZsXzc3N8cYbb4x7/s6dO+P666+PH//4x9HV1RX19fXx2c9+Nn71q1994MUDAPkz6wGgNMqyLMuKuaChoSEuv/zyeOihhyIiYmRkJOrr6+O2226LNWvW/MHrh4eHY/r06fHQQw/F8uXLT+o++/v7o6amJvr6+qK6urqY5QJA7k73uWTWA0BpZlNRz4APDQ3F7t27o6mp6fdfoLw8mpqaoqur66S+xltvvRVvv/12nHvuuSc8Z3BwMPr7+8fcAIDSM+sBoHSKCvAjR47E8PBw1NbWjjleW1sbPT09J/U17rjjjpg9e/aYwf5ebW1tUVNTM3qrr68vZpkAwASZ9QBQOknfBX3jxo2xdevWePrpp6OqquqE561duzb6+vpGb4cOHUq4SgBgosx6ADixacWcPGPGjKioqIje3t4xx3t7e6Ouru59r73//vtj48aN8aMf/SguvfTS9z23UChEoVAoZmkAQA7MegAonaKeAa+srIwFCxZEZ2fn6LGRkZHo7OyMxsbGE1533333xb333hsdHR2xcOHCia8WACgpsx4ASqeoZ8AjIlpaWmLFihWxcOHCWLRoUWzatCkGBgZi5cqVERGxfPnymDNnTrS1tUVExD/90z/F+vXr44knnoi5c+eO/v7YRz7ykfjIRz6S40MBAPJg1gNAaRQd4EuXLo3Dhw/H+vXro6enJ+bPnx8dHR2jb9Zy8ODBKC///RPr3/rWt2JoaCj++q//eszXaW1tja9+9asfbPUAQO7MegAojaI/B3wy+GxQAKYScyl/9hSAqWbSPwccAAAAmBgBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAkIcAAAAEhAgAMAAEACAhwAAAASEOAAAACQgAAHAACABAQ4AAAAJCDAAQAAIAEBDgAAAAlMKMDb29tj7ty5UVVVFQ0NDbFr1673Pf/73/9+XHTRRVFVVRWXXHJJ7NixY0KLBQDSMOsBIH9FB/i2bduipaUlWltbY8+ePTFv3rxobm6ON954Y9zzX3jhhbj++uvjxhtvjL1798aSJUtiyZIl8fOf//wDLx4AyJ9ZDwClUZZlWVbMBQ0NDXH55ZfHQw89FBERIyMjUV9fH7fddlusWbPmuPOXLl0aAwMD8cMf/nD02J//+Z/H/PnzY/PmzSd1n/39/VFTUxN9fX1RXV1dzHIBIHen+1wy6wGgNLNpWjEnDw0Nxe7du2Pt2rWjx8rLy6OpqSm6urrGvaarqytaWlrGHGtubo5nnnnmhPczODgYg4ODo3/u6+uLiHc2AAAm27vzqMifYZ8SzHoAeEcp5n1RAX7kyJEYHh6O2traMcdra2tj//79417T09Mz7vk9PT0nvJ+2tra45557jjteX19fzHIBoKT++7//O2pqaiZ7Gbky6wFgrDznfVEBnsratWvH/CT9zTffjI9+9KNx8ODB0+4fOpOhv78/6uvr49ChQ17mlxN7mi/7mT97mq++vr4477zz4txzz53spZyyzPrS8/c+X/Yzf/Y0X/Yzf6WY90UF+IwZM6KioiJ6e3vHHO/t7Y26urpxr6mrqyvq/IiIQqEQhULhuOM1NTW+mXJUXV1tP3NmT/NlP/NnT/NVXn76fZqnWX/68fc+X/Yzf/Y0X/Yzf3nO+6K+UmVlZSxYsCA6OztHj42MjERnZ2c0NjaOe01jY+OY8yMinnvuuROeDwBMHrMeAEqn6Jegt7S0xIoVK2LhwoWxaNGi2LRpUwwMDMTKlSsjImL58uUxZ86caGtri4iI22+/Pa6++up44IEH4rrrroutW7fGz372s3jkkUfyfSQAQC7MegAojaIDfOnSpXH48OFYv3599PT0xPz586Ojo2P0zVcOHjw45in6K664Ip544om466674s4774w/+7M/i2eeeSYuvvjik77PQqEQra2t475UjeLZz/zZ03zZz/zZ03yd7vtp1p8e7Gm+7Gf+7Gm+7Gf+SrGnRX8OOAAAAFC80+/dYwAAAGAKEuAAAACQgAAHAACABAQ4AAAAJDBlAry9vT3mzp0bVVVV0dDQELt27Xrf87///e/HRRddFFVVVXHJJZfEjh07Eq301FDMfm7ZsiWuuuqqmD59ekyfPj2ampr+4P5/GBX7PfqurVu3RllZWSxZsqS0CzzFFLufb775ZqxatSpmzZoVhUIhLrzwQn/v36PYPd20aVN8/OMfjzPPPDPq6+tj9erV8bvf/S7Raqe2n/zkJ7F48eKYPXt2lJWVxTPPPPMHr9m5c2d8+tOfjkKhEB/72Mfi8ccfL/k6TzVmfb7M+vyZ9fkz7/Nl1udn0mZ9NgVs3bo1q6yszB577LHsP//zP7Obb745O+ecc7Le3t5xz//pT3+aVVRUZPfdd1/20ksvZXfddVd2xhlnZC+++GLilU9Nxe7nDTfckLW3t2d79+7N9u3bl/3t3/5tVlNTk/3Xf/1X4pVPXcXu6btee+21bM6cOdlVV12V/dVf/VWaxZ4Cit3PwcHBbOHChdm1116bPf/889lrr72W7dy5M+vu7k688qmr2D397ne/mxUKhey73/1u9tprr2XPPvtsNmvWrGz16tWJVz417dixI1u3bl321FNPZRGRPf300+97/oEDB7Kzzjora2lpyV566aXsm9/8ZlZRUZF1dHSkWfApwKzPl1mfP7M+f+Z9vsz6fE3WrJ8SAb5o0aJs1apVo38eHh7OZs+enbW1tY17/uc///nsuuuuG3OsoaEh+7u/+7uSrvNUUex+vtexY8eys88+O/vOd75TqiWeciayp8eOHcuuuOKK7Nvf/na2YsUKQ/n/KXY/v/Wtb2Xnn39+NjQ0lGqJp5xi93TVqlXZX/zFX4w51tLSkl155ZUlXeep6GSG8le+8pXsU5/61JhjS5cuzZqbm0u4slOLWZ8vsz5/Zn3+zPt8mfWlk3LWT/pL0IeGhmL37t3R1NQ0eqy8vDyampqiq6tr3Gu6urrGnB8R0dzcfMLzP0wmsp/v9dZbb8Xbb78d5557bqmWeUqZ6J5+7Wtfi5kzZ8aNN96YYpmnjIns5w9+8INobGyMVatWRW1tbVx88cWxYcOGGB4eTrXsKW0ie3rFFVfE7t27R1+6duDAgdixY0dce+21SdZ8ujGX3p9Zny+zPn9mff7M+3yZ9ZMvr7k0Lc9FTcSRI0dieHg4amtrxxyvra2N/fv3j3tNT0/PuOf39PSUbJ2nions53vdcccdMXv27OO+wT6sJrKnzz//fDz66KPR3d2dYIWnlons54EDB+Lf//3f4wtf+ELs2LEjXn311fjSl74Ub7/9drS2tqZY9pQ2kT294YYb4siRI/GZz3wmsiyLY8eOxa233hp33nlniiWfdk40l/r7++O3v/1tnHnmmZO0sqnBrM+XWZ8/sz5/5n2+zPrJl9esn/RnwJlaNm7cGFu3bo2nn346qqqqJns5p6SjR4/GsmXLYsuWLTFjxozJXs5pYWRkJGbOnBmPPPJILFiwIJYuXRrr1q2LzZs3T/bSTlk7d+6MDRs2xMMPPxx79uyJp556KrZv3x733nvvZC8NKDGz/oMz60vDvM+XWT81Tfoz4DNmzIiKioro7e0dc7y3tzfq6urGvaaurq6o8z9MJrKf77r//vtj48aN8aMf/SguvfTSUi7zlFLsnv7iF7+I119/PRYvXjx6bGRkJCIipk2bFi+//HJccMEFpV30FDaR79FZs2bFGWecERUVFaPHPvGJT0RPT08MDQ1FZWVlSdc81U1kT+++++5YtmxZ3HTTTRERcckll8TAwEDccsstsW7duigv9/PZYpxoLlVXV3/on/2OMOvzZtbnz6zPn3mfL7N+8uU16yd91ysrK2PBggXR2dk5emxkZCQ6OzujsbFx3GsaGxvHnB8R8dxzz53w/A+TiexnRMR9990X9957b3R0dMTChQtTLPWUUeyeXnTRRfHiiy9Gd3f36O1zn/tcXHPNNdHd3R319fUplz/lTOR79Morr4xXX3119B83ERGvvPJKzJo160M9jN81kT196623jhu87/6D5533IqEY5tL7M+vzZdbnz6zPn3mfL7N+8uU2l4p6y7YS2bp1a1YoFLLHH388e+mll7JbbrklO+ecc7Kenp4sy7Js2bJl2Zo1a0bP/+lPf5pNmzYtu//++7N9+/Zlra2tPprk/yl2Pzdu3JhVVlZmTz75ZPbrX/969Hb06NHJeghTTrF7+l7eGXWsYvfz4MGD2dlnn539/d//ffbyyy9nP/zhD7OZM2dmX//61yfrIUw5xe5pa2trdvbZZ2f/+q//mh04cCD7t3/7t+yCCy7IPv/5z0/WQ5hSjh49mu3duzfbu3dvFhHZgw8+mO3duzf75S9/mWVZlq1ZsyZbtmzZ6PnvfjTJP/7jP2b79u3L2tvbfQzZe5j1+TLr82fW58+8z5dZn6/JmvVTIsCzLMu++c1vZuedd15WWVmZLVq0KPuP//iP0f929dVXZytWrBhz/ve+973swgsvzCorK7NPfepT2fbt2xOveGorZj8/+tGPZhFx3K21tTX9wqewYr9H/z9D+XjF7ucLL7yQNTQ0ZIVCITv//POzb3zjG9mxY8cSr3pqK2ZP33777eyrX/1qdsEFF2RVVVVZfX199qUvfSn7n//5n/QLn4J+/OMfj/v/xXf3cMWKFdnVV1993DXz58/PKisrs/PPPz/7l3/5l+TrnurM+nyZ9fkz6/Nn3ufLrM/PZM36sizz+gMAAAAotUn/HXAAAAD4MBDgAAAAkIAABwAAgAQEOAAAACQgwAEAACABAQ4AAAAJCHAAAABIQIADAABAAgIcAAAAEhDgAAAAkIAABwAAgAQEOAAAACTwf/lIfjxBw0/5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset splitting\n",
    "sentiment_labels = imdb_data['sentiment'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(imdb_data.review, sentiment_labels, test_size=0.2)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "for idx, group in enumerate([('Train', y_train), ('Test', y_test)]):\n",
    "    data = group[1].value_counts()\n",
    "    sns.barplot(ax=ax[idx], x=data.index, y=data.values)\n",
    "    ax[idx].set_title(f'{group[0]} Label Count')\n",
    "    ax[idx].set_xlabel(f'{group[0]} Labels')\n",
    "    ax[idx].set_ylabel('Label Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(train: list, test: list) -> tuple[list, list]:\n",
    "    '''Method to use the Bag of Words (BOW) method to calculate the occurrence of words within a document\n",
    "    \n",
    "    Required Args\n",
    "        train (list): Training dataset of movie reviews\n",
    "        test (list): Testing dataset of movie reviews\n",
    "    \n",
    "    Returns\n",
    "        list: Transformed training dataset reviews\n",
    "        list: Transformed Testing dataset reviews\n",
    "    '''\n",
    "    # Initialize vectorizer\n",
    "    cv=CountVectorizer()\n",
    "    # Transform training dataset\n",
    "    transformed_train=cv.fit_transform(train)\n",
    "    # Transform testing dataset\n",
    "    transformed_test=cv.transform(test)\n",
    "    return transformed_train, transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW Vectorization\n",
    "bow_transformed_train, bow_transformed_test = bow(x_train, x_test)\n",
    "print('BOW Train: ', bow_transformed_train.shape)\n",
    "print('BOW Test: ', bow_transformed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb6510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(train: list, test: list) -> tuple[list, list]:\n",
    "    '''Method to use the Term Frequency Inverse Document Frequency (TF-IDF) method to calculate how relevant a word in a series or corpus is to a text\n",
    "    \n",
    "    Required Args\n",
    "        train (list): Training dataset of movie reviews\n",
    "        test (list): Testing dataset of movie reviews\n",
    "    \n",
    "    Returns\n",
    "        list: Transformed training dataset reviews\n",
    "        list: Transformed Testing dataset reviews\n",
    "    '''\n",
    "    # Initialize vectorizer\n",
    "    tfidf=TfidfVectorizer()\n",
    "    # Transform training dataset\n",
    "    transformed_train=tfidf.fit_transform(train)\n",
    "    # Transform testing dataset\n",
    "    transformed_test=tfidf.transform(test)\n",
    "    return transformed_train, transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c17b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_transformed_train, tfidf_transformed_test = tfidf(x_train, x_test)\n",
    "print('TFIDF Train: ', tfidf_transformed_train.shape)\n",
    "print('TFIDF Test: ', tfidf_transformed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW + Multinomial Naive Bayes Classifier\n",
    "bow_nb_start = time.time()\n",
    "bow_nb = MultinomialNB()\n",
    "bow_nb.fit(bow_transformed_train, y_train)\n",
    "bow_nb_end = time.time()\n",
    "bow_nb_y_pred = bow_nb.predict(bow_transformed_test)\n",
    "print(classification_report(y_test, bow_nb_y_pred))\n",
    "print()\n",
    "print('Spending time: ', bow_nb_end - bow_nb_start)\n",
    "print()\n",
    "bow_nb_cm = confusion_matrix(y_test, bow_nb_y_pred)\n",
    "bow_nb_cm_display = ConfusionMatrixDisplay(confusion_matrix=bow_nb_cm, display_labels=[False, True])\n",
    "bow_nb_cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW + Neural Network\n",
    "bow_nn_start = time.time()\n",
    "bow_nn = models.Sequential()\n",
    "# Input - Layer\n",
    "bow_nn.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "# Hidden - Layers\n",
    "bow_nn.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "bow_nn.add(layers.Dense(50, activation = \"relu\"))\n",
    "bow_nn.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "bow_nn.add(layers.Dense(50, activation = \"relu\"))\n",
    "# Output- Layer\n",
    "bow_nn.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "# Compilation\n",
    "bow_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bow_nn.fit(bow_transformed_train, y_train)\n",
    "bow_nn_end = time.time()\n",
    "bow_nn_y_pred = bow_nn.predict(bow_transformed_test)\n",
    "print(classification_report(y_test, bow_nn_y_pred))\n",
    "print()\n",
    "print('Spending time: ', bow_nn_end - bow_nn_start)\n",
    "print()\n",
    "bow_nn_cm = confusion_matrix(y_test, bow_nn_y_pred)\n",
    "bow_nn_cm_display = ConfusionMatrixDisplay(confusion_matrix=bow_nn_cm, display_labels=[False, True])\n",
    "bow_nn_cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a959dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + Naive Bayes Classifier\n",
    "tfidf_nb_start = time.time()\n",
    "tfidf_nb = MultinomialNB()\n",
    "tfidf_nb.fit(tfidf_transformed_train, y_train)\n",
    "tfidf_nb_end = time.time()\n",
    "tfidf_nb_y_pred = tfidf_nb.predict(tfidf_transformed_test)\n",
    "print('===== TFIDF + Naive Bayes Classifier =====')\n",
    "print(classification_report(y_test, tfidf_nb_y_pred))\n",
    "print()\n",
    "print('Spending time: ', tfidf_nb_start - tfidf_nb_end)\n",
    "print()\n",
    "tfidf_nb_cm = confusion_matrix(y_test, tfidf_nb_y_pred)\n",
    "tfidf_nb_cm_display = ConfusionMatrixDisplay(confusion_matrix=tfidf_nb_cm, display_labels=[False, True])\n",
    "tfidf_nb_cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + Neural Network\n",
    "tfidf_nn_start = time.time()\n",
    "tfidf_nn = models.Sequential()\n",
    "# Input - Layer\n",
    "tfidf_nn.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "# Hidden - Layers\n",
    "tfidf_nn.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "tfidf_nn.add(layers.Dense(50, activation = \"relu\"))\n",
    "tfidf_nn.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "tfidf_nn.add(layers.Dense(50, activation = \"relu\"))\n",
    "# Output- Layer\n",
    "tfidf_nn.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "# Compilation\n",
    "tfidf_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "tfidf_nn.fit(bow_transformed_train, y_train)\n",
    "tfidf_nn_end = time.time()\n",
    "tfidf_nn_y_pred = bow_nn.predict(bow_transformed_test)\n",
    "print(classification_report(y_test, tfidf_nn_y_pred))\n",
    "print()\n",
    "print('Spending time: ', tfidf_nn_end - tfidf_nn_start)\n",
    "print()\n",
    "tfidf_nn_cm = confusion_matrix(y_test, tfidf_nn_y_pred)\n",
    "tfidf_nn_cm_display = ConfusionMatrixDisplay(confusion_matrix=tfidf_nn_cm, display_labels=[False, True])\n",
    "tfidf_nn_cm_display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
