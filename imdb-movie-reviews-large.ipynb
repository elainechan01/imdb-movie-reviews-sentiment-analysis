{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be737ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.4.4)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.5.4-cp310-cp310-macosx_11_0_arm64.whl (6.6 MB)\n",
      "Requirement already satisfied: contractions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.1.73)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: spacy-cleaner in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.1.3)\n",
      "Requirement already satisfied: pyspellchecker in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.7.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.64.1)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.13.1)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0rc2-cp310-cp310-macosx_12_0_arm64.whl (2.0 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (63.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4) (2.4.1)\n",
      "Requirement already satisfied: spacy-lookups-data<1.1.0,>=1.0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy-cleaner) (1.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Collecting tensorflow-macos==2.13.0-rc2 (from tensorflow)\n",
      "  Downloading tensorflow_macos-2.13.0rc2-cp310-cp310-macosx_12_0_arm64.whl (189.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting astunparse>=1.6.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading h5py-3.9.0-cp310-cp310-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading libclang-16.0.0-py2.py3-none-macosx_11_0_arm64.whl (24.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc2->tensorflow) (4.21.12)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc2->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-macosx_11_0_arm64.whl (36 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc2->tensorflow) (1.51.1)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0rc0 (from tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyascii in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0-rc2->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (0.8.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow)\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc2->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-estimator, tensorboard-data-server, opt-einsum, markdown, h5py, google-pasta, gast, astunparse, absl-py, tensorboard, tensorflow-macos, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.6.3\n",
      "    Uninstalling typing_extensions-4.6.3:\n",
      "      Successfully uninstalled typing_extensions-4.6.3\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.4.0 google-pasta-0.2.0 h5py-3.9.0 libclang-16.0.0 markdown-3.4.3 opt-einsum-3.3.0 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0rc2 tensorflow-estimator-2.13.0 tensorflow-macos-2.13.0rc2 termcolor-2.3.0 typing-extensions-4.5.0 werkzeug-2.3.6 wrapt-1.15.0\n",
      "Collecting en-core-web-lg==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from en-core-web-lg==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (63.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip3 install -U spacy contractions beautifulsoup4 spacy-cleaner pyspellchecker requests pandas scikit-learn tqdm matplotlib seaborn keras tensorflow\n",
    "!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ccf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "from spellchecker import SpellChecker\n",
    "import en_core_web_lg\n",
    "import spacy\n",
    "import requests\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e464ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "5  Probably my all-time favorite movie, a story o...  positive\n",
      "6  I sure would like to see a resurrection of a u...  positive\n",
      "7  This show was an amazing, fresh & innovative i...  negative\n",
      "8  Encouraged by the positive comments about this...  negative\n",
      "9  If you like original gut wrenching laughter yo...  positive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory data analysis\n",
    "imdb_data = pd.read_csv('input/imdb_dataset.csv')\n",
    "print(imdb_data.head(10))\n",
    "imdb_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfdaac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slang_dict() -> dict:\n",
    "    '''Method to retrieve a dictionary of slang phrases and its actual meanings\n",
    "    \n",
    "    Returns\n",
    "        str: Tokenized text\n",
    "    '''\n",
    "    abbr_dict = {}\n",
    "    def getAbbr(alpha, abbr_dict):\n",
    "        res = requests.get('https://www.noslang.com/dictionary/'+alpha)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        for abbr in soup.find_all('abbr'):\n",
    "            full = abbr['title'].lower()\n",
    "            abrv = abbr.find('dt').text[:-2]\n",
    "            abbr_dict[abrv] = full\n",
    "    abbr_list = []\n",
    "    for char in range(97,123):\n",
    "        abbr_list.append(chr(char))\n",
    "    for i in abbr_list:\n",
    "        getAbbr(i, abbr_dict)\n",
    "    return abbr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1333671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_review(review: str) -> str:\n",
    "    '''Method to normalize (preprocess and lemmatize) a review into a tokenized list of words\n",
    "    Steps:\n",
    "        1. HTML decoding\n",
    "        2. Lowercase conversion\n",
    "        3. Contractions expansion\n",
    "        4. Entities detection\n",
    "        5. Digits and punctuations removal\n",
    "        5. Slang correction\n",
    "        6. Spelling correction\n",
    "        7. Word tokenization\n",
    "        8. Stop words removal and removal of insignificant words (less than 2 characters)\n",
    "        9. Lemmatization\n",
    "    \n",
    "    Required Args\n",
    "        review (str): Text to be preprocessed\n",
    "    \n",
    "    Returns\n",
    "        str: Tokenized text\n",
    "    '''\n",
    "    # HTML decoding\n",
    "    review = BeautifulSoup(review).get_text()\n",
    "    # Convert words to lowercase\n",
    "    review = review.lower()\n",
    "    # Expand contractions\n",
    "    review_list = []\n",
    "    for word in review.split():\n",
    "        review_list.append(contractions.fix(word))\n",
    "    review = ' '.join(review_list)\n",
    "    # Make entities a single token eg. New York -> New-York\n",
    "    nlp = en_core_web_lg.load()\n",
    "    entity_list = []\n",
    "    for ele in nlp(review).ents:\n",
    "        if len(str(ele.text).split()) > 1:\n",
    "            entity_list.append((ele.text, str(ele.text).replace(' ','_')))\n",
    "    for item in entity_list:\n",
    "        review = review.replace(item[0], item[1])\n",
    "    # Digits and punctuations removal\n",
    "    review_list = re.sub('[^a-zA-Z0-9_]', ' ', review).split()\n",
    "    review_list = [word for word in review_list if not re.search(r'\\d', word)]\n",
    "    review = ' '.join(review_list)\n",
    "    # Correct slang words / phrases\n",
    "    global abbr_dict\n",
    "    expanded = {}\n",
    "    for word in review_list:\n",
    "        if word in abbr_dict:\n",
    "            expanded[word] = abbr_dict[word]\n",
    "    for item in expanded:\n",
    "        review = review.replace(item, expanded[item])\n",
    "    # Correct spelling\n",
    "    review_list = review.split()\n",
    "    corrector = SpellChecker()\n",
    "    misspelled = corrector.unknown(review_list)\n",
    "    corrected = {}\n",
    "    for word in misspelled:\n",
    "        if corrector.correction(word):\n",
    "            corrected[word] = corrector.correction(word)\n",
    "    review = ' '.join(review_list)\n",
    "    for item in corrected:\n",
    "        review = review.replace(item, corrected[item])\n",
    "    # Word tokenization, stop word removal and lemmatization\n",
    "    doc = nlp(review)\n",
    "    tokenized_word_list = []\n",
    "    for token in doc:\n",
    "        if '_' in token.text:\n",
    "            tokenized_word_list.append(token.text)\n",
    "        elif not token.is_stop and len(token.text) > 1:\n",
    "            # Lemmatization\n",
    "            tokenized_word_list.append(token.lemma_)\n",
    "    return ' '.join(tokenized_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f969884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/_nztlx510ng_bk9rwth0cg280000gn/T/ipykernel_86298/1609383967.py:22: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review = BeautifulSoup(review).get_text()\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "abbr_dict = get_slang_dict()\n",
    "imdb_data['review'] = imdb_data['review'].apply(normalize_review)\n",
    "imdb_data = imdb_data[['review', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73497690",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset splitting\n",
    "sentiment_labels = imdb_data['sentiment'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(imdb_data.review, sentiment_labels, test_size=0.2)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "for idx, group in enumerate([('Train', y_train), ('Test', y_test)]):\n",
    "    data = group[1].value_counts()\n",
    "    sns.barplot(ax=ax[idx], x=data.index, y=data.values)\n",
    "    ax[idx].set_title(f'{group[0]} Label Count')\n",
    "    ax[idx].set_xlabel(f'{group[0]} Labels')\n",
    "    ax[idx].set_ylabel('Label Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(train: list, test: list) -> tuple[list, list]:\n",
    "    '''Method to use the Bag of Words (BOW) method to calculate the occurrence of words within a document\n",
    "    \n",
    "    Required Args\n",
    "        train (list): Training dataset of movie reviews\n",
    "        test (list): Testing dataset of movie reviews\n",
    "    \n",
    "    Returns\n",
    "        list: Transformed training dataset reviews\n",
    "        list: Transformed Testing dataset reviews\n",
    "    '''\n",
    "    # Initialize vectorizer\n",
    "    cv=CountVectorizer()\n",
    "    # Transform training dataset\n",
    "    transformed_train=cv.fit_transform(train)\n",
    "    # Transform testing dataset\n",
    "    transformed_test=cv.transform(test)\n",
    "    return transformed_train, transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf1e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW Vectorization\n",
    "bow_transformed_train, bow_transformed_test = bow(x_train, x_test)\n",
    "print('BOW Train: ', bow_transformed_train.shape)\n",
    "print('BOW Test: ', bow_transformed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb6510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(train: list, test: list) -> tuple[list, list]:\n",
    "    '''Method to use the Term Frequency Inverse Document Frequency (TF-IDF) method to calculate how relevant a word in a series or corpus is to a text\n",
    "    \n",
    "    Required Args\n",
    "        train (list): Training dataset of movie reviews\n",
    "        test (list): Testing dataset of movie reviews\n",
    "    \n",
    "    Returns\n",
    "        list: Transformed training dataset reviews\n",
    "        list: Transformed Testing dataset reviews\n",
    "    '''\n",
    "    # Initialize vectorizer\n",
    "    tfidf=TfidfVectorizer()\n",
    "    # Transform training dataset\n",
    "    transformed_train=tfidf.fit_transform(train)\n",
    "    # Transform testing dataset\n",
    "    transformed_test=tfidf.transform(test)\n",
    "    return transformed_train, transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3bd325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_transformed_train, tfidf_transformed_test = tfidf(x_train, x_test)\n",
    "print('TFIDF Train: ', tfidf_transformed_train.shape)\n",
    "print('TFIDF Test: ', tfidf_transformed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bca2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW + Multinomial Naive Bayes Classifier\n",
    "bow_nb_start = time.time()\n",
    "bow_nb = MultinomialNB()\n",
    "bow_nb.fit(bow_transformed_train, y_train)\n",
    "bow_nb_end = time.time()\n",
    "bow_nb_y_pred = bow_nb.predict(bow_transformed_test)\n",
    "print(classification_report(y_test, bow_nb_y_pred))\n",
    "print()\n",
    "print('Spending time: ', bow_nb_end - bow_nb_start)\n",
    "print()\n",
    "bow_nb_cm = confusion_matrix(y_test, bow_nb_y_pred)\n",
    "bow_nb_cm_display = ConfusionMatrixDisplay(confusion_matrix=bow_nb_cm, display_labels=[False, True])\n",
    "bow_nb_cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0cc417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW + Neural Network\n",
    "bow_nn_start = time.time()\n",
    "bow_nn = models.Sequential()\n",
    "# Input - Layer\n",
    "bow_nn.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "# Hidden - Layers\n",
    "bow_nn.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "bow_nn.add(layers.Dense(50, activation = \"relu\"))\n",
    "bow_nn.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "bow_nn.add(layers.Dense(50, activation = \"relu\"))\n",
    "# Output- Layer\n",
    "bow_nn.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "# Compilation\n",
    "bow_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bow_nn.fit(bow_transformed_train, y_train)\n",
    "bow_nn_end = time.time()\n",
    "bow_nn_y_pred = bow_nn.predict(bow_transformed_test)\n",
    "print(classification_report(y_test, bow_nn_y_pred))\n",
    "print()\n",
    "print('Spending time: ', bow_nn_end - bow_nn_start)\n",
    "print()\n",
    "bow_nn_cm = confusion_matrix(y_test, bow_nn_y_pred)\n",
    "bow_nn_cm_display = ConfusionMatrixDisplay(confusion_matrix=bow_nn_cm, display_labels=[False, True])\n",
    "bow_nn_cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf212108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + Naive Bayes Classifier\n",
    "tfidf_nb_start = time.time()\n",
    "tfidf_nb = MultinomialNB()\n",
    "tfidf_nb.fit(tfidf_transformed_train, y_train)\n",
    "tfidf_nb_end = time.time()\n",
    "tfidf_nb_y_pred = tfidf_nb.predict(tfidf_transformed_test)\n",
    "print('===== TFIDF + Naive Bayes Classifier =====')\n",
    "print(classification_report(y_test, tfidf_nb_y_pred))\n",
    "print()\n",
    "print('Spending time: ', tfidf_nb_start - tfidf_nb_end)\n",
    "print()\n",
    "tfidf_nb_cm = confusion_matrix(y_test, tfidf_nb_y_pred)\n",
    "tfidf_nb_cm_display = ConfusionMatrixDisplay(confusion_matrix=tfidf_nb_cm, display_labels=[False, True])\n",
    "tfidf_nb_cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91004695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + Neural Network\n",
    "tfidf_nn_start = time.time()\n",
    "tfidf_nn = models.Sequential()\n",
    "# Input - Layer\n",
    "tfidf_nn.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "# Hidden - Layers\n",
    "tfidf_nn.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "tfidf_nn.add(layers.Dense(50, activation = \"relu\"))\n",
    "tfidf_nn.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "tfidf_nn.add(layers.Dense(50, activation = \"relu\"))\n",
    "# Output- Layer\n",
    "tfidf_nn.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "# Compilation\n",
    "tfidf_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "tfidf_nn.fit(bow_transformed_train, y_train)\n",
    "tfidf_nn_end = time.time()\n",
    "tfidf_nn_y_pred = bow_nn.predict(bow_transformed_test)\n",
    "print(classification_report(y_test, tfidf_nn_y_pred))\n",
    "print()\n",
    "print('Spending time: ', tfidf_nn_end - tfidf_nn_start)\n",
    "print()\n",
    "tfidf_nn_cm = confusion_matrix(y_test, tfidf_nn_y_pred)\n",
    "tfidf_nn_cm_display = ConfusionMatrixDisplay(confusion_matrix=tfidf_nn_cm, display_labels=[False, True])\n",
    "tfidf_nn_cm_display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
