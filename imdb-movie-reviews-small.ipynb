{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip3 install -U spacy contractions beautifulsoup4 spacy-cleaner pyspellchecker requests pandas scikit-learn tqdm matplotlib seaborn keras tensorflow\n",
    "!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7869afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "from spellchecker import SpellChecker\n",
    "import en_core_web_lg\n",
    "import spacy\n",
    "import requests\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory data analysis\n",
    "imdb_data = pd.read_csv('input/imdb_dataset.csv')\n",
    "print(imdb_data.head(10))\n",
    "imdb_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_review(review: str) -> str:\n",
    "    '''Method to normalize (preprocess and lemmatize) a review into a tokenized list of words\n",
    "    Steps:\n",
    "      1. HTML decoding\n",
    "      2. Lowercase conversion\n",
    "      3. Contractions expansion\n",
    "      4. Digits and punctuations removal\n",
    "      5. Word tokenization\n",
    "      6. Stop words removal and removal of insignificant words (less than 2 characters)\n",
    "      7. Lemmatization\n",
    "\n",
    "    Required Args\n",
    "      review (str): Text to be preprocessed\n",
    "\n",
    "  Returns\n",
    "      str: Tokenized text\n",
    "  '''\n",
    "  # HTML decoding\n",
    "  review = BeautifulSoup(review).get_text()\n",
    "  # Convert words to lowercase\n",
    "  review = review.lower()\n",
    "  # Expand contractions\n",
    "  review_list = []\n",
    "  for word in review.split():\n",
    "      review_list.append(contractions.fix(word))\n",
    "  review = ' '.join(review_list)\n",
    "  # Digits and punctuations removal\n",
    "  review_list = re.sub('[^a-zA-Z0-9_]', ' ', review).split()\n",
    "  review_list = [word for word in review_list if not re.search(r'\\d', word)]\n",
    "  review = ' '.join(review_list)\n",
    "  # Word tokenization, stop word removal and lemmatization\n",
    "  nlp = en_core_web_lg.load()\n",
    "  doc = nlp(review)\n",
    "  tokenized_word_list = []\n",
    "  for token in doc:\n",
    "      if '_' in token.text:\n",
    "          tokenized_word_list.append(token.text)\n",
    "      elif not token.is_stop and len(token.text) > 1:\n",
    "          # Lemmatization\n",
    "          tokenized_word_list.append(token.lemma_)\n",
    "  return ' '.join(tokenized_word_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
